{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "see README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7776,
     "status": "ok",
     "timestamp": 1526105952629,
     "user": {
      "displayName": "Chengwei Zhang",
      "photoUrl": "//lh5.googleusercontent.com/-FK2ckwmh6mM/AAAAAAAAAAI/AAAAAAAAPLw/SX9b1QAzJ5g/s50-c-k-no/photo.jpg",
      "userId": "114808171854651597062"
     },
     "user_tz": -480
    },
    "id": "1wsDPx682A7H",
    "outputId": "88ee055c-b674-4a81-c869-8401551f09d7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools\n",
    "\n",
    "\n",
    "import datetime\n",
    "\n",
    "import editdistance\n",
    "import numpy as np\n",
    "\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import Input, Dense, Activation\n",
    "from keras.layers import Reshape, Lambda\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing import image\n",
    "import keras.callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Xnj6R_OE3yMl"
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIR = 'image_ocr'\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "mM0eHsJO5bP6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code under development ...\n",
      "click debug in visual studio code\n"
     ]
    }
   ],
   "source": [
    "# Text_Image is the original generator. It creates images programaticaly. \n",
    "# Script_Image takes handwritten words from the IAM database.\n",
    "generator_choice =  \"Script_Image\" # \"Text_Image\" #\n",
    "import generator_text_image as GTI\n",
    "import generator_iam_words as IAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "HBLwtxF35f0c"
   },
   "outputs": [],
   "source": [
    "import ctc_drop_first_2\n",
    "import cnn_rnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "YOAsKfXm5jP1"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# For a real OCR application, this should be beam search with a dictionary\n",
    "# and language model.  For this example, best path is sufficient.\n",
    "\n",
    "def decode_batch(test_func, word_batch):\n",
    "    out = test_func([word_batch])[0]\n",
    "    ret = []\n",
    "    for j in range(out.shape[0]):\n",
    "        out_best = list(np.argmax(out[j, 2:], 1))\n",
    "        out_best = [k for k, g in itertools.groupby(out_best)]\n",
    "        if generator_choice ==  \"Script_Image\":\n",
    "            outstr = IAM.labels_to_text(out_best)\n",
    "        else:\n",
    "            outstr = GTI.labels_to_text(out_best)\n",
    "        ret.append(outstr)\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "KcGtIsLF5leW"
   },
   "outputs": [],
   "source": [
    "class VizCallback(keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, run_name, test_func, text_img_gen, num_display_words=6):\n",
    "        self.test_func = test_func\n",
    "        self.output_dir = os.path.join(\n",
    "            OUTPUT_DIR, run_name)\n",
    "        self.text_img_gen = text_img_gen\n",
    "        self.num_display_words = num_display_words\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "\n",
    "    def show_edit_distance(self, num):\n",
    "        num_left = num\n",
    "        mean_norm_ed = 0.0\n",
    "        mean_ed = 0.0\n",
    "        while num_left > 0:\n",
    "            word_batch = next(self.text_img_gen)[0]\n",
    "            num_proc = min(word_batch['the_input'].shape[0], num_left)\n",
    "            decoded_res = decode_batch(self.test_func, word_batch['the_input'][0:num_proc])\n",
    "            for j in range(num_proc):\n",
    "                edit_dist = editdistance.eval(decoded_res[j], word_batch['source_str'][j])\n",
    "                mean_ed += float(edit_dist)\n",
    "                mean_norm_ed += float(edit_dist) / len(word_batch['source_str'][j])\n",
    "            num_left -= num_proc\n",
    "        mean_norm_ed = mean_norm_ed / num\n",
    "        mean_ed = mean_ed / num\n",
    "        print('\\nOut of %d samples:  Mean edit distance: %.3f Mean normalized edit distance: %0.3f'\n",
    "              % (num, mean_ed, mean_norm_ed))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.model.save_weights(os.path.join(self.output_dir, 'weights%02d.h5' % (epoch)))\n",
    "        self.show_edit_distance(256)\n",
    "        word_batch = next(self.text_img_gen)[0]\n",
    "        res = decode_batch(self.test_func, word_batch['the_input'][0:self.num_display_words])\n",
    "        if word_batch['the_input'][0].shape[0] < 256:\n",
    "            cols = 2\n",
    "        else:\n",
    "            cols = 1\n",
    "        for i in range(self.num_display_words):\n",
    "            plt.subplot(self.num_display_words // cols, cols, i + 1)\n",
    "            if K.image_data_format() == 'channels_first':\n",
    "                the_input = word_batch['the_input'][i, 0, :, :]\n",
    "            else:\n",
    "                the_input = word_batch['the_input'][i, :, :, 0]\n",
    "            plt.imshow(the_input.T, cmap='Greys_r')\n",
    "            plt.xlabel('Truth = \\'%s\\'\\nDecoded = \\'%s\\'' % (word_batch['source_str'][i], res[i]))\n",
    "        fig = pylab.gcf()\n",
    "        fig.set_size_inches(10, 13)\n",
    "        plt.savefig(os.path.join(self.output_dir, 'e%02d.png' % (epoch)))\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "eC4vEfcQ5oOq"
   },
   "outputs": [],
   "source": [
    "img_gen = None\n",
    "def train(run_name, start_epoch, stop_epoch, img_w):\n",
    "    global img_gen\n",
    "    img_h = 64\n",
    "    \n",
    "    # Input Parameters\n",
    "\n",
    "    words_per_epoch = 16000\n",
    "    val_split = 0.2\n",
    "    \n",
    "    # 16000 * 0.2 = 3200\n",
    "    val_words = int(words_per_epoch * (val_split))\n",
    "\n",
    "    # Network parameters\n",
    "    minibatch_size = 32\n",
    "    pool_size = 2\n",
    "    \n",
    "    # (16000 - 3200) // 32 = 400\n",
    "    steps_per_epoch = (words_per_epoch - val_words) // minibatch_size\n",
    "\n",
    "\n",
    "    if generator_choice == \"Text_Image\":\n",
    "        fdir = os.path.dirname(get_file('wordlists.tgz',\n",
    "                                        origin='http://www.mythic-ai.com/datasets/wordlists.tgz', untar=True))\n",
    "\n",
    "        img_gen = GTI.TextImageGenerator(monogram_file=os.path.join(fdir, 'wordlist_mono_clean.txt'),\n",
    "                                     bigram_file=os.path.join(fdir, 'wordlist_bi_clean.txt'),\n",
    "                                     minibatch_size=minibatch_size,\n",
    "                                     img_w=img_w,\n",
    "                                     img_h=img_h,\n",
    "                                     downsample_factor=(pool_size ** 2),\n",
    "                                     val_split=words_per_epoch - val_words\n",
    "                                     )\n",
    "    elif generator_choice == \"Script_Image\":\n",
    "        img_gen = IAM.IAM_Word_Generator(minibatch_size = 32, img_w = 128, img_h = 64, downsample_factor=4, absolute_max_string_len=16)\n",
    "    else:\n",
    "        assert False\n",
    "\n",
    "    model, input_data, y_pred = cnn_rnn_model.make_model(img_w, img_h, pool_size, img_gen.get_output_size(), img_gen.absolute_max_string_len)\n",
    "    \n",
    "    \n",
    "    model.summary() # print summary of model\n",
    "\n",
    "    # clipnorm seems to speeds up convergence\n",
    "    sgd = SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n",
    "    \n",
    "    # the loss calc occurs elsewhere, so use a dummy lambda func for the loss\n",
    "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd)\n",
    "    if start_epoch > 0:\n",
    "        weight_file = os.path.join(OUTPUT_DIR, os.path.join(run_name, 'weights%02d.h5' % (start_epoch - 1)))\n",
    "        model.load_weights(weight_file)\n",
    "    # captures output of softmax so we can decode the output during visualization\n",
    "    test_func = K.function([input_data], [y_pred])\n",
    "\n",
    "    viz_cb = VizCallback(run_name, test_func, img_gen.next_val())\n",
    "\n",
    "    model.fit_generator(generator=img_gen.next_train(),\n",
    "                        steps_per_epoch=steps_per_epoch,\n",
    "                        epochs=stop_epoch,\n",
    "                        validation_data=img_gen.next_val(),\n",
    "                        validation_steps=val_words // minibatch_size,\n",
    "                        callbacks=[viz_cb, img_gen],\n",
    "                        initial_epoch=start_epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "13kO-MxI7XWb"
   },
   "source": [
    "### Start the training\n",
    "\n",
    "1080ti run times: \n",
    "- 12 minutes for 20/20 epoch\n",
    "- 25 minutes for 25/25 epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2094
    },
    "colab_type": "code",
    "id": "YRGglF5L5qzn",
    "outputId": "541e795b-80d1-49e6-9c9f-e2014690f4a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "Tensor(\"the_labels:0\", shape=(?, 16), dtype=float32)\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:4249: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py:4229: to_int64 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_input (InputLayer)          (None, 128, 64, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 128, 64, 16)  160         the_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max1 (MaxPooling2D)             (None, 64, 32, 16)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 64, 32, 16)   2320        max1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "max2 (MaxPooling2D)             (None, 32, 16, 16)   0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 32, 256)      0           max2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 32, 32)       8224        reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru1 (GRU)                      (None, 32, 512)      837120      dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru1_b (GRU)                    (None, 32, 512)      837120      dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_1 (Add)                     (None, 32, 512)      0           gru1[0][0]                       \n",
      "                                                                 gru1_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru2 (GRU)                      (None, 32, 512)      1574400     add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gru2_b (GRU)                    (None, 32, 512)      1574400     add_1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 32, 1024)     0           gru2[0][0]                       \n",
      "                                                                 gru2_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 32, 54)       55350       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, 32, 54)       0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "the_labels (InputLayer)         (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "label_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ctc (Lambda)                    (None, 1)            0           softmax[0][0]                    \n",
      "                                                                 the_labels[0][0]                 \n",
      "                                                                 input_length[0][0]               \n",
      "                                                                 label_length[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 4,889,094\n",
      "Trainable params: 4,889,094\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "WARNING:tensorflow:From /usr/local/lib/python3.5/dist-packages/tensorflow/python/ops/math_grad.py:102: div (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Deprecated in favor of operator or tf.math.divide.\n",
      "on_train_begin\n",
      "Epoch 1/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 36s 89ms/step - loss: 12.6063 - val_loss: 10.9665\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 2.484 Mean normalized edit distance: 0.842\n",
      "Epoch 2/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 33s 82ms/step - loss: 9.5254 - val_loss: 8.6299\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 2.234 Mean normalized edit distance: 0.670\n",
      "Epoch 3/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 33s 82ms/step - loss: 7.9735 - val_loss: 7.6821\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 2.031 Mean normalized edit distance: 0.617\n",
      "Epoch 4/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 33s 82ms/step - loss: 7.0530 - val_loss: 6.7169\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 1.781 Mean normalized edit distance: 0.503\n",
      "Epoch 5/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 33s 82ms/step - loss: 6.5251 - val_loss: 6.4904\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 1.738 Mean normalized edit distance: 0.519\n",
      "Epoch 6/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 33s 82ms/step - loss: 6.0083 - val_loss: 5.6863\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 1.457 Mean normalized edit distance: 0.417\n",
      "Epoch 7/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 33s 82ms/step - loss: 5.6703 - val_loss: 5.6125\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 1.484 Mean normalized edit distance: 0.434\n",
      "Epoch 8/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 81ms/step - loss: 5.3927 - val_loss: 5.2517\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 1.379 Mean normalized edit distance: 0.383\n",
      "Epoch 9/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 33s 83ms/step - loss: 5.1563 - val_loss: 5.1290\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 1.410 Mean normalized edit distance: 0.388\n",
      "Epoch 10/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 33s 82ms/step - loss: 4.7725 - val_loss: 4.6889\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 1.332 Mean normalized edit distance: 0.341\n",
      "Epoch 11/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 33s 81ms/step - loss: 4.5949 - val_loss: 4.5986\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.965 Mean normalized edit distance: 0.282\n",
      "Epoch 12/200\n",
      "on_epoch_begin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 32s 79ms/step - loss: 4.4421 - val_loss: 4.5507\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 1.176 Mean normalized edit distance: 0.319\n",
      "Epoch 13/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 4.2834 - val_loss: 4.3134\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 1.262 Mean normalized edit distance: 0.349\n",
      "Epoch 14/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 4.2023 - val_loss: 4.0855\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 1.242 Mean normalized edit distance: 0.300\n",
      "Epoch 15/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 4.0699 - val_loss: 3.8709\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.961 Mean normalized edit distance: 0.284\n",
      "Epoch 16/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 3.8251 - val_loss: 3.6475\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 1.012 Mean normalized edit distance: 0.252\n",
      "Epoch 17/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 3.6019 - val_loss: 3.4995\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.969 Mean normalized edit distance: 0.244\n",
      "Epoch 18/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 3.4397 - val_loss: 3.4998\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.902 Mean normalized edit distance: 0.243\n",
      "Epoch 19/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 3.3457 - val_loss: 3.2631\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.809 Mean normalized edit distance: 0.226\n",
      "Epoch 20/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 3.2284 - val_loss: 3.1831\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.957 Mean normalized edit distance: 0.235\n",
      "Epoch 21/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 3.1300 - val_loss: 3.0475\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.992 Mean normalized edit distance: 0.237\n",
      "Epoch 22/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 31s 79ms/step - loss: 2.9824 - val_loss: 2.9025\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.797 Mean normalized edit distance: 0.192\n",
      "Epoch 23/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 81ms/step - loss: 2.9618 - val_loss: 2.8328\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.652 Mean normalized edit distance: 0.174\n",
      "Epoch 24/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 2.8751 - val_loss: 2.8258\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.699 Mean normalized edit distance: 0.177\n",
      "Epoch 25/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 2.7076 - val_loss: 2.6089\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.688 Mean normalized edit distance: 0.192\n",
      "Epoch 26/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 2.6756 - val_loss: 2.5998\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.773 Mean normalized edit distance: 0.190\n",
      "Epoch 27/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 2.6227 - val_loss: 2.5170\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.738 Mean normalized edit distance: 0.183\n",
      "Epoch 28/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 2.5690 - val_loss: 2.6124\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.824 Mean normalized edit distance: 0.217\n",
      "Epoch 29/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 2.5537 - val_loss: 2.2811\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.789 Mean normalized edit distance: 0.190\n",
      "Epoch 30/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 2.5075 - val_loss: 2.3324\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.699 Mean normalized edit distance: 0.203\n",
      "Epoch 31/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 2.3609 - val_loss: 2.4471\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.719 Mean normalized edit distance: 0.170\n",
      "Epoch 32/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 2.2591 - val_loss: 2.2915\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.609 Mean normalized edit distance: 0.149\n",
      "Epoch 33/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 2.2200 - val_loss: 2.2283\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.656 Mean normalized edit distance: 0.168\n",
      "Epoch 34/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 2.1522 - val_loss: 2.1888\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.535 Mean normalized edit distance: 0.142\n",
      "Epoch 35/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 2.1602 - val_loss: 2.0638\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.637 Mean normalized edit distance: 0.158\n",
      "Epoch 36/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 2.1340 - val_loss: 2.1443\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.562 Mean normalized edit distance: 0.140\n",
      "Epoch 37/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 2.1039 - val_loss: 2.0420\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.582 Mean normalized edit distance: 0.136\n",
      "Epoch 38/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 2.0553 - val_loss: 1.8736\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.508 Mean normalized edit distance: 0.148\n",
      "Epoch 39/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 2.0617 - val_loss: 1.8114\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.465 Mean normalized edit distance: 0.112\n",
      "Epoch 40/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.9422 - val_loss: 1.9258\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.539 Mean normalized edit distance: 0.150\n",
      "Epoch 41/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.9447 - val_loss: 1.8933\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.531 Mean normalized edit distance: 0.149\n",
      "Epoch 42/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.8180 - val_loss: 1.7677\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.633 Mean normalized edit distance: 0.178\n",
      "Epoch 43/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.8098 - val_loss: 2.0469\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.660 Mean normalized edit distance: 0.156\n",
      "Epoch 44/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.8736 - val_loss: 1.7768\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.484 Mean normalized edit distance: 0.124\n",
      "Epoch 45/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.7930 - val_loss: 1.7165\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.590 Mean normalized edit distance: 0.139\n",
      "Epoch 46/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.8483 - val_loss: 1.7515\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.508 Mean normalized edit distance: 0.139\n",
      "Epoch 47/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.6818 - val_loss: 1.5707\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.473 Mean normalized edit distance: 0.129\n",
      "Epoch 48/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 80ms/step - loss: 1.7146 - val_loss: 1.6165\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.473 Mean normalized edit distance: 0.115\n",
      "Epoch 49/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.7237 - val_loss: 1.7479\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.379 Mean normalized edit distance: 0.110\n",
      "Epoch 50/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 80ms/step - loss: 1.6045 - val_loss: 1.6808\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.457 Mean normalized edit distance: 0.122\n",
      "Epoch 51/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.5990 - val_loss: 1.6048\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.379 Mean normalized edit distance: 0.089\n",
      "Epoch 52/200\n",
      "on_epoch_begin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 32s 79ms/step - loss: 1.6130 - val_loss: 1.4386\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.320 Mean normalized edit distance: 0.089\n",
      "Epoch 53/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.5730 - val_loss: 1.5184\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.426 Mean normalized edit distance: 0.095\n",
      "Epoch 54/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.5864 - val_loss: 1.4752\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.465 Mean normalized edit distance: 0.127\n",
      "Epoch 55/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.5955 - val_loss: 1.5887\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.449 Mean normalized edit distance: 0.105\n",
      "Epoch 56/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.5564 - val_loss: 1.4568\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.484 Mean normalized edit distance: 0.129\n",
      "Epoch 57/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.5778 - val_loss: 1.4109\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.359 Mean normalized edit distance: 0.092\n",
      "Epoch 58/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.4496 - val_loss: 1.4187\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.402 Mean normalized edit distance: 0.112\n",
      "Epoch 59/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.4907 - val_loss: 1.3117\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.367 Mean normalized edit distance: 0.087\n",
      "Epoch 60/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.4233 - val_loss: 1.5767\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.434 Mean normalized edit distance: 0.113\n",
      "Epoch 61/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.4430 - val_loss: 1.5658\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.391 Mean normalized edit distance: 0.095\n",
      "Epoch 62/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.4791 - val_loss: 1.2344\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.367 Mean normalized edit distance: 0.095\n",
      "Epoch 63/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 31s 79ms/step - loss: 1.3831 - val_loss: 1.3195\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.574 Mean normalized edit distance: 0.138\n",
      "Epoch 64/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.3322 - val_loss: 1.3944\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.445 Mean normalized edit distance: 0.119\n",
      "Epoch 65/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.4442 - val_loss: 1.5576\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.434 Mean normalized edit distance: 0.118\n",
      "Epoch 66/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 80ms/step - loss: 1.3758 - val_loss: 1.3958\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.383 Mean normalized edit distance: 0.088\n",
      "Epoch 67/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.4083 - val_loss: 1.1887\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.340 Mean normalized edit distance: 0.089\n",
      "Epoch 68/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.3272 - val_loss: 1.2330\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.395 Mean normalized edit distance: 0.102\n",
      "Epoch 69/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 80ms/step - loss: 1.3301 - val_loss: 1.2297\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.352 Mean normalized edit distance: 0.088\n",
      "Epoch 70/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 80ms/step - loss: 1.2837 - val_loss: 1.2966\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.375 Mean normalized edit distance: 0.093\n",
      "Epoch 71/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.2973 - val_loss: 1.3961\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.340 Mean normalized edit distance: 0.092\n",
      "Epoch 72/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.3889 - val_loss: 1.2714\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.289 Mean normalized edit distance: 0.071\n",
      "Epoch 73/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.3470 - val_loss: 1.4061\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.484 Mean normalized edit distance: 0.127\n",
      "Epoch 74/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.3208 - val_loss: 1.2497\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.309 Mean normalized edit distance: 0.075\n",
      "Epoch 75/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.3254 - val_loss: 1.2358\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.305 Mean normalized edit distance: 0.074\n",
      "Epoch 76/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.3391 - val_loss: 1.2222\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.352 Mean normalized edit distance: 0.096\n",
      "Epoch 77/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.3192 - val_loss: 1.6420\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.512 Mean normalized edit distance: 0.136\n",
      "Epoch 78/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.1908 - val_loss: 1.2852\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.297 Mean normalized edit distance: 0.071\n",
      "Epoch 79/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.2937 - val_loss: 1.1880\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.383 Mean normalized edit distance: 0.081\n",
      "Epoch 80/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.3507 - val_loss: 1.2662\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.340 Mean normalized edit distance: 0.094\n",
      "Epoch 81/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.3436 - val_loss: 1.2412\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.301 Mean normalized edit distance: 0.082\n",
      "Epoch 82/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 80ms/step - loss: 1.2549 - val_loss: 1.1470\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.434 Mean normalized edit distance: 0.098\n",
      "Epoch 83/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.2255 - val_loss: 1.2198\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.324 Mean normalized edit distance: 0.083\n",
      "Epoch 84/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.2330 - val_loss: 0.9906\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.289 Mean normalized edit distance: 0.077\n",
      "Epoch 85/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.1601 - val_loss: 1.4430\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.430 Mean normalized edit distance: 0.102\n",
      "Epoch 86/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.2675 - val_loss: 2.6060\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.805 Mean normalized edit distance: 0.245\n",
      "Epoch 87/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.1939 - val_loss: 1.1265\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.297 Mean normalized edit distance: 0.085\n",
      "Epoch 88/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.1847 - val_loss: 1.1965\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.371 Mean normalized edit distance: 0.084\n",
      "Epoch 89/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 80ms/step - loss: 1.1646 - val_loss: 1.6024\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.422 Mean normalized edit distance: 0.113\n",
      "Epoch 90/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 80ms/step - loss: 1.1230 - val_loss: 1.0450\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.328 Mean normalized edit distance: 0.082\n",
      "Epoch 91/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 80ms/step - loss: 1.2214 - val_loss: 1.2519\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.371 Mean normalized edit distance: 0.098\n",
      "Epoch 92/200\n",
      "on_epoch_begin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 32s 79ms/step - loss: 1.2574 - val_loss: 1.3209\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.406 Mean normalized edit distance: 0.123\n",
      "Epoch 93/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.2031 - val_loss: 1.0529\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.395 Mean normalized edit distance: 0.104\n",
      "Epoch 94/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 31s 79ms/step - loss: 1.1856 - val_loss: 0.9743\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.258 Mean normalized edit distance: 0.071\n",
      "Epoch 95/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.2532 - val_loss: 1.1716\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.336 Mean normalized edit distance: 0.081\n",
      "Epoch 96/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.1458 - val_loss: 1.0144\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.297 Mean normalized edit distance: 0.077\n",
      "Epoch 97/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.1515 - val_loss: 1.0317\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.242 Mean normalized edit distance: 0.065\n",
      "Epoch 98/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 80ms/step - loss: 1.1713 - val_loss: 1.1050\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.328 Mean normalized edit distance: 0.076\n",
      "Epoch 99/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 80ms/step - loss: 1.3167 - val_loss: 1.1055\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.457 Mean normalized edit distance: 0.112\n",
      "Epoch 100/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.2337 - val_loss: 1.0506\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.324 Mean normalized edit distance: 0.092\n",
      "Epoch 101/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.1597 - val_loss: 1.1541\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.395 Mean normalized edit distance: 0.097\n",
      "Epoch 102/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.1109 - val_loss: 1.1375\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.285 Mean normalized edit distance: 0.078\n",
      "Epoch 103/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.2101 - val_loss: 1.0469\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.352 Mean normalized edit distance: 0.077\n",
      "Epoch 104/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.1862 - val_loss: 1.1260\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.352 Mean normalized edit distance: 0.089\n",
      "Epoch 105/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.1481 - val_loss: 1.3044\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.430 Mean normalized edit distance: 0.106\n",
      "Epoch 106/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.1083 - val_loss: 1.0164\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.324 Mean normalized edit distance: 0.088\n",
      "Epoch 107/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.2283 - val_loss: 3.4142\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.824 Mean normalized edit distance: 0.234\n",
      "Epoch 108/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 80ms/step - loss: 1.2595 - val_loss: 1.2623\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.348 Mean normalized edit distance: 0.072\n",
      "Epoch 109/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.2579 - val_loss: 1.1546\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.418 Mean normalized edit distance: 0.094\n",
      "Epoch 110/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 80ms/step - loss: 1.2111 - val_loss: 1.1057\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.328 Mean normalized edit distance: 0.083\n",
      "Epoch 111/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 80ms/step - loss: 1.2627 - val_loss: 1.0525\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.312 Mean normalized edit distance: 0.090\n",
      "Epoch 112/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.1489 - val_loss: 3.2750\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.750 Mean normalized edit distance: 0.203\n",
      "Epoch 113/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.1714 - val_loss: 1.1805\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.469 Mean normalized edit distance: 0.114\n",
      "Epoch 114/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.1610 - val_loss: 1.1056\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.320 Mean normalized edit distance: 0.076\n",
      "Epoch 115/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.1753 - val_loss: 1.0468\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.281 Mean normalized edit distance: 0.063\n",
      "Epoch 116/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.2260 - val_loss: 1.1982\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.348 Mean normalized edit distance: 0.095\n",
      "Epoch 117/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.1384 - val_loss: 1.0880\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.262 Mean normalized edit distance: 0.068\n",
      "Epoch 118/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.2692 - val_loss: 0.9718\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.320 Mean normalized edit distance: 0.085\n",
      "Epoch 119/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.2565 - val_loss: 1.0782\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.270 Mean normalized edit distance: 0.074\n",
      "Epoch 120/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.2240 - val_loss: 1.6795\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.473 Mean normalized edit distance: 0.126\n",
      "Epoch 121/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.4065 - val_loss: 1.0220\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.340 Mean normalized edit distance: 0.083\n",
      "Epoch 122/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 80ms/step - loss: 1.2237 - val_loss: 0.9835\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.320 Mean normalized edit distance: 0.073\n",
      "Epoch 123/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 80ms/step - loss: 1.1607 - val_loss: 3.1695\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.828 Mean normalized edit distance: 0.241\n",
      "Epoch 124/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.2329 - val_loss: 1.0605\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.227 Mean normalized edit distance: 0.052\n",
      "Epoch 125/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.1874 - val_loss: 1.1921\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.336 Mean normalized edit distance: 0.085\n",
      "Epoch 126/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.1695 - val_loss: 0.9910\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.348 Mean normalized edit distance: 0.091\n",
      "Epoch 127/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.1930 - val_loss: 1.1918\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.324 Mean normalized edit distance: 0.084\n",
      "Epoch 128/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.1937 - val_loss: 0.9092\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.262 Mean normalized edit distance: 0.068\n",
      "Epoch 129/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 80ms/step - loss: 1.3127 - val_loss: 1.1482\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.348 Mean normalized edit distance: 0.106\n",
      "Epoch 130/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 80ms/step - loss: 1.3978 - val_loss: 1.0319\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.301 Mean normalized edit distance: 0.075\n",
      "Epoch 131/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.3201 - val_loss: 1.0950\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.375 Mean normalized edit distance: 0.103\n",
      "Epoch 132/200\n",
      "on_epoch_begin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 32s 80ms/step - loss: 1.2514 - val_loss: 1.2792\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.348 Mean normalized edit distance: 0.089\n",
      "Epoch 133/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.1689 - val_loss: 1.1048\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.430 Mean normalized edit distance: 0.103\n",
      "Epoch 134/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.1812 - val_loss: 1.1309\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.355 Mean normalized edit distance: 0.103\n",
      "Epoch 135/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.2753 - val_loss: 1.2610\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.355 Mean normalized edit distance: 0.085\n",
      "Epoch 136/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 80ms/step - loss: 1.2781 - val_loss: 1.2460\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.324 Mean normalized edit distance: 0.085\n",
      "Epoch 137/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.1480 - val_loss: 1.1929\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.410 Mean normalized edit distance: 0.105\n",
      "Epoch 138/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 80ms/step - loss: 1.1657 - val_loss: 0.9313\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.355 Mean normalized edit distance: 0.092\n",
      "Epoch 139/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 80ms/step - loss: 1.1964 - val_loss: 2.0184\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.648 Mean normalized edit distance: 0.191\n",
      "Epoch 140/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.3520 - val_loss: 1.6231\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.449 Mean normalized edit distance: 0.111\n",
      "Epoch 141/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.2398 - val_loss: 1.1041\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.309 Mean normalized edit distance: 0.084\n",
      "Epoch 142/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 80ms/step - loss: 1.1696 - val_loss: 1.1129\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.359 Mean normalized edit distance: 0.079\n",
      "Epoch 143/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.1438 - val_loss: 1.4676\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.469 Mean normalized edit distance: 0.133\n",
      "Epoch 144/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.4268 - val_loss: 1.2062\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.430 Mean normalized edit distance: 0.117\n",
      "Epoch 145/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.2692 - val_loss: 1.6155\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.516 Mean normalized edit distance: 0.136\n",
      "Epoch 146/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.2432 - val_loss: 1.1047\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.449 Mean normalized edit distance: 0.112\n",
      "Epoch 147/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.3376 - val_loss: 1.0071\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.297 Mean normalized edit distance: 0.070\n",
      "Epoch 148/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.2172 - val_loss: 1.1565\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.391 Mean normalized edit distance: 0.103\n",
      "Epoch 149/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.1690 - val_loss: 1.8520\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.512 Mean normalized edit distance: 0.146\n",
      "Epoch 150/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.2314 - val_loss: 1.1451\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.289 Mean normalized edit distance: 0.075\n",
      "Epoch 151/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.2079 - val_loss: 1.5451\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.465 Mean normalized edit distance: 0.126\n",
      "Epoch 152/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 80ms/step - loss: 1.1811 - val_loss: 1.0264\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.301 Mean normalized edit distance: 0.075\n",
      "Epoch 153/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.2073 - val_loss: 1.2044\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.312 Mean normalized edit distance: 0.087\n",
      "Epoch 154/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 80ms/step - loss: 1.2428 - val_loss: 1.0923\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.348 Mean normalized edit distance: 0.080\n",
      "Epoch 155/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 80ms/step - loss: 1.2125 - val_loss: 1.2031\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.402 Mean normalized edit distance: 0.103\n",
      "Epoch 156/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 81ms/step - loss: 1.4029 - val_loss: 1.0298\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.312 Mean normalized edit distance: 0.082\n",
      "Epoch 157/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 80ms/step - loss: 1.5359 - val_loss: 1.0890\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.328 Mean normalized edit distance: 0.086\n",
      "Epoch 158/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.2762 - val_loss: 1.6209\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.359 Mean normalized edit distance: 0.094\n",
      "Epoch 159/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 2.0835 - val_loss: 1.2184\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.391 Mean normalized edit distance: 0.089\n",
      "Epoch 160/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.1975 - val_loss: 0.9846\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.371 Mean normalized edit distance: 0.095\n",
      "Epoch 161/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.2347 - val_loss: 1.3446\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.371 Mean normalized edit distance: 0.085\n",
      "Epoch 162/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.1912 - val_loss: 1.2560\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.473 Mean normalized edit distance: 0.127\n",
      "Epoch 163/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.3979 - val_loss: 1.2666\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.316 Mean normalized edit distance: 0.081\n",
      "Epoch 164/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.2773 - val_loss: 1.2177\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.391 Mean normalized edit distance: 0.098\n",
      "Epoch 165/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.3121 - val_loss: 2.6621\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.641 Mean normalized edit distance: 0.198\n",
      "Epoch 166/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.3864 - val_loss: 1.3466\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.340 Mean normalized edit distance: 0.093\n",
      "Epoch 167/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.3856 - val_loss: 3.3235\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.746 Mean normalized edit distance: 0.213\n",
      "Epoch 168/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.3634 - val_loss: 1.1624\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.379 Mean normalized edit distance: 0.098\n",
      "Epoch 169/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.2246 - val_loss: 1.2177\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.352 Mean normalized edit distance: 0.090\n",
      "Epoch 170/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.2651 - val_loss: 1.1114\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.418 Mean normalized edit distance: 0.105\n",
      "Epoch 171/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.2820 - val_loss: 1.1635\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.371 Mean normalized edit distance: 0.089\n",
      "Epoch 172/200\n",
      "on_epoch_begin\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "400/400 [==============================] - 32s 79ms/step - loss: 1.1916 - val_loss: 1.1030\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.352 Mean normalized edit distance: 0.096\n",
      "Epoch 173/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.5161 - val_loss: 1.2014\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.312 Mean normalized edit distance: 0.087\n",
      "Epoch 174/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.3063 - val_loss: 1.4894\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.422 Mean normalized edit distance: 0.109\n",
      "Epoch 175/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.3005 - val_loss: 1.2645\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.465 Mean normalized edit distance: 0.120\n",
      "Epoch 176/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.2419 - val_loss: 4.4700\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 1.039 Mean normalized edit distance: 0.271\n",
      "Epoch 177/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.3974 - val_loss: 1.2747\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.379 Mean normalized edit distance: 0.100\n",
      "Epoch 178/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.3583 - val_loss: 1.2475\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.438 Mean normalized edit distance: 0.102\n",
      "Epoch 179/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 80ms/step - loss: 1.6128 - val_loss: 1.1635\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.348 Mean normalized edit distance: 0.082\n",
      "Epoch 180/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 80ms/step - loss: 1.2738 - val_loss: 1.1344\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.355 Mean normalized edit distance: 0.098\n",
      "Epoch 181/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.4139 - val_loss: 1.1751\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.438 Mean normalized edit distance: 0.096\n",
      "Epoch 182/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 80ms/step - loss: 1.4376 - val_loss: 1.2829\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.359 Mean normalized edit distance: 0.091\n",
      "Epoch 183/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.4242 - val_loss: 1.2370\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.387 Mean normalized edit distance: 0.100\n",
      "Epoch 184/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.3452 - val_loss: 1.4386\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.418 Mean normalized edit distance: 0.110\n",
      "Epoch 185/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 79ms/step - loss: 1.3504 - val_loss: 1.1721\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.391 Mean normalized edit distance: 0.095\n",
      "Epoch 186/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 81ms/step - loss: 1.4667 - val_loss: 1.1657\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.465 Mean normalized edit distance: 0.113\n",
      "Epoch 187/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 33s 82ms/step - loss: 1.5999 - val_loss: 1.2161\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.410 Mean normalized edit distance: 0.122\n",
      "Epoch 188/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 33s 83ms/step - loss: 1.3055 - val_loss: 1.1216\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.426 Mean normalized edit distance: 0.098\n",
      "Epoch 189/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 33s 81ms/step - loss: 1.4573 - val_loss: 1.5603\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.570 Mean normalized edit distance: 0.147\n",
      "Epoch 190/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 33s 83ms/step - loss: 1.3405 - val_loss: 1.1880\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.426 Mean normalized edit distance: 0.109\n",
      "Epoch 191/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 33s 82ms/step - loss: 1.3572 - val_loss: 4.8183\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 1.301 Mean normalized edit distance: 0.386\n",
      "Epoch 192/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 33s 82ms/step - loss: 1.3948 - val_loss: 1.4028\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.414 Mean normalized edit distance: 0.110\n",
      "Epoch 193/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 33s 82ms/step - loss: 1.7674 - val_loss: 1.2286\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.293 Mean normalized edit distance: 0.079\n",
      "Epoch 194/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 81ms/step - loss: 1.3182 - val_loss: 1.1839\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.305 Mean normalized edit distance: 0.087\n",
      "Epoch 195/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 33s 82ms/step - loss: 1.6009 - val_loss: 1.2997\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.289 Mean normalized edit distance: 0.083\n",
      "Epoch 196/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 34s 85ms/step - loss: 1.4371 - val_loss: 1.4863\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.566 Mean normalized edit distance: 0.147\n",
      "Epoch 197/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 34s 85ms/step - loss: 1.2952 - val_loss: 1.1974\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.336 Mean normalized edit distance: 0.092\n",
      "Epoch 198/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 34s 84ms/step - loss: 1.4970 - val_loss: 1.3911\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.430 Mean normalized edit distance: 0.110\n",
      "Epoch 199/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 34s 84ms/step - loss: 1.3501 - val_loss: 1.1498\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.320 Mean normalized edit distance: 0.081\n",
      "Epoch 200/200\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 34s 85ms/step - loss: 1.8883 - val_loss: 1.7781\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.547 Mean normalized edit distance: 0.156\n",
      "Tensor(\"the_labels_1:0\", shape=(?, 16), dtype=float32)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_input (InputLayer)          (None, 512, 64, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 512, 64, 16)  160         the_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max1 (MaxPooling2D)             (None, 256, 32, 16)  0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 256, 32, 16)  2320        max1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "max2 (MaxPooling2D)             (None, 128, 16, 16)  0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 128, 256)     0           max2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 128, 32)      8224        reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru1 (GRU)                      (None, 128, 512)     837120      dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru1_b (GRU)                    (None, 128, 512)     837120      dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_2 (Add)                     (None, 128, 512)     0           gru1[0][0]                       \n",
      "                                                                 gru1_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru2 (GRU)                      (None, 128, 512)     1574400     add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gru2_b (GRU)                    (None, 128, 512)     1574400     add_2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 128, 1024)    0           gru2[0][0]                       \n",
      "                                                                 gru2_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 128, 54)      55350       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, 128, 54)      0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "the_labels (InputLayer)         (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "label_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ctc (Lambda)                    (None, 1)            0           softmax[0][0]                    \n",
      "                                                                 the_labels[0][0]                 \n",
      "                                                                 input_length[0][0]               \n",
      "                                                                 label_length[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 4,889,094\n",
      "Trainable params: 4,889,094\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "on_train_begin\n",
      "Epoch 21/25\n",
      "on_epoch_begin\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Error when checking input: expected the_input to have shape (512, 64, 1) but got array with shape (128, 64, 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-7c83b8d13604>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# increase to wider images and start at epoch 20. The learned weights are reloaded\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mimg_gen\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_img_w\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m512\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-7-6d30df9c8edb>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(run_name, start_epoch, stop_epoch, img_w)\u001b[0m\n\u001b[1;32m     61\u001b[0m                         \u001b[0mvalidation_steps\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mval_words\u001b[0m \u001b[0;34m//\u001b[0m \u001b[0mminibatch_size\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m                         \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mviz_cb\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mimg_gen\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m                         initial_epoch=start_epoch)\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/legacy/interfaces.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m                 warnings.warn('Update your `' + object_name + '` call to the ' +\n\u001b[1;32m     90\u001b[0m                               'Keras 2 API: ' + signature, stacklevel=2)\n\u001b[0;32m---> 91\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     92\u001b[0m         \u001b[0mwrapper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_original_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     93\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m   1416\u001b[0m             \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1417\u001b[0m             \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1418\u001b[0;31m             initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m   1419\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1420\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0minterfaces\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlegacy_generator_methods_support\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_generator.py\u001b[0m in \u001b[0;36mfit_generator\u001b[0;34m(model, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[1;32m    215\u001b[0m                 outs = model.train_on_batch(x, y,\n\u001b[1;32m    216\u001b[0m                                             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 217\u001b[0;31m                                             class_weight=class_weight)\n\u001b[0m\u001b[1;32m    218\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight)\u001b[0m\n\u001b[1;32m   1209\u001b[0m             \u001b[0mx\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1210\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1211\u001b[0;31m             class_weight=class_weight)\n\u001b[0m\u001b[1;32m   1212\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_uses_dynamic_learning_phase\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1213\u001b[0m             \u001b[0mins\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0msample_weights\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;36m1.\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_standardize_user_data\u001b[0;34m(self, x, y, sample_weight, class_weight, check_array_lengths, batch_size)\u001b[0m\n\u001b[1;32m    749\u001b[0m             \u001b[0mfeed_input_shapes\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    750\u001b[0m             \u001b[0mcheck_batch_axis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0;31m# Don't enforce the batch size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 751\u001b[0;31m             exception_prefix='input')\n\u001b[0m\u001b[1;32m    752\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    753\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0my\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training_utils.py\u001b[0m in \u001b[0;36mstandardize_input_data\u001b[0;34m(data, names, shapes, check_batch_axis, exception_prefix)\u001b[0m\n\u001b[1;32m    136\u001b[0m                             \u001b[0;34m': expected '\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mnames\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' to have shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m                             \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m' but got array with shape '\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 138\u001b[0;31m                             str(data_shape))\n\u001b[0m\u001b[1;32m    139\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: Error when checking input: expected the_input to have shape (512, 64, 1) but got array with shape (128, 64, 1)"
     ]
    }
   ],
   "source": [
    "run_name = datetime.datetime.now().strftime('%Y:%m:%d:%H:%M:%S')\n",
    "train(run_name, 0, 200, 128)\n",
    "# increase to wider images and start at epoch 20. The learned weights are reloaded\n",
    "img_gen.set_img_w(512)\n",
    "train(run_name, 20, 25, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "image_ocr.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
