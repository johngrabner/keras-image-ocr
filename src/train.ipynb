{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "see README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7776,
     "status": "ok",
     "timestamp": 1526105952629,
     "user": {
      "displayName": "Chengwei Zhang",
      "photoUrl": "//lh5.googleusercontent.com/-FK2ckwmh6mM/AAAAAAAAAAI/AAAAAAAAPLw/SX9b1QAzJ5g/s50-c-k-no/photo.jpg",
      "userId": "114808171854651597062"
     },
     "user_tz": -480
    },
    "id": "1wsDPx682A7H",
    "outputId": "88ee055c-b674-4a81-c869-8401551f09d7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools\n",
    "\n",
    "\n",
    "import datetime\n",
    "\n",
    "import editdistance\n",
    "import numpy as np\n",
    "\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import Input, Dense, Activation\n",
    "from keras.layers import Reshape, Lambda\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing import image\n",
    "import keras.callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Xnj6R_OE3yMl"
   },
   "outputs": [],
   "source": [
    "OUTPUT_DIR = 'image_ocr'\n",
    "\n",
    "\n",
    "\n",
    "np.random.seed(55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "mM0eHsJO5bP6"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "code under development ...\n",
      "click debug in visual studio code\n"
     ]
    }
   ],
   "source": [
    "# Text_Image is the original generator. It creates images programaticaly. \n",
    "# Script_Image takes handwritten words from the IAM database.\n",
    "generator_choice =  \"Script_Image\" # \"Text_Image\" #\n",
    "import generator_text_image as GTI\n",
    "import generator_iam_words as IAM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "HBLwtxF35f0c"
   },
   "outputs": [],
   "source": [
    "import ctc_drop_first_2\n",
    "import cnn_rnn_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "YOAsKfXm5jP1"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "# For a real OCR application, this should be beam search with a dictionary\n",
    "# and language model.  For this example, best path is sufficient.\n",
    "\n",
    "def decode_batch(test_func, word_batch):\n",
    "    out = test_func([word_batch])[0]\n",
    "    ret = []\n",
    "    for j in range(out.shape[0]):\n",
    "        out_best = list(np.argmax(out[j, 2:], 1))\n",
    "        out_best = [k for k, g in itertools.groupby(out_best)]\n",
    "        if generator_choice ==  \"Script_Image\":\n",
    "            outstr = IAM.labels_to_text(out_best)\n",
    "        else:\n",
    "            outstr = GTI.labels_to_text(out_best)\n",
    "        ret.append(outstr)\n",
    "    return ret\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "KcGtIsLF5leW"
   },
   "outputs": [],
   "source": [
    "class VizCallback(keras.callbacks.Callback):\n",
    "\n",
    "    def __init__(self, run_name, test_func, text_img_gen, num_display_words=6):\n",
    "        self.test_func = test_func\n",
    "        self.output_dir = os.path.join(\n",
    "            OUTPUT_DIR, run_name)\n",
    "        self.text_img_gen = text_img_gen\n",
    "        self.num_display_words = num_display_words\n",
    "        if not os.path.exists(self.output_dir):\n",
    "            os.makedirs(self.output_dir)\n",
    "\n",
    "    def show_edit_distance(self, num):\n",
    "        num_left = num\n",
    "        mean_norm_ed = 0.0\n",
    "        mean_ed = 0.0\n",
    "        while num_left > 0:\n",
    "            word_batch = next(self.text_img_gen)[0]\n",
    "            num_proc = min(word_batch['the_input'].shape[0], num_left)\n",
    "            decoded_res = decode_batch(self.test_func, word_batch['the_input'][0:num_proc])\n",
    "            for j in range(num_proc):\n",
    "                edit_dist = editdistance.eval(decoded_res[j], word_batch['source_str'][j])\n",
    "                mean_ed += float(edit_dist)\n",
    "                mean_norm_ed += float(edit_dist) / len(word_batch['source_str'][j])\n",
    "            num_left -= num_proc\n",
    "        mean_norm_ed = mean_norm_ed / num\n",
    "        mean_ed = mean_ed / num\n",
    "        print('\\nOut of %d samples:  Mean edit distance: %.3f Mean normalized edit distance: %0.3f'\n",
    "              % (num, mean_ed, mean_norm_ed))\n",
    "\n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        self.model.save_weights(os.path.join(self.output_dir, 'weights%02d.h5' % (epoch)))\n",
    "        self.show_edit_distance(256)\n",
    "        word_batch = next(self.text_img_gen)[0]\n",
    "        res = decode_batch(self.test_func, word_batch['the_input'][0:self.num_display_words])\n",
    "        if word_batch['the_input'][0].shape[0] < 256:\n",
    "            cols = 2\n",
    "        else:\n",
    "            cols = 1\n",
    "        for i in range(self.num_display_words):\n",
    "            plt.subplot(self.num_display_words // cols, cols, i + 1)\n",
    "            if K.image_data_format() == 'channels_first':\n",
    "                the_input = word_batch['the_input'][i, 0, :, :]\n",
    "            else:\n",
    "                the_input = word_batch['the_input'][i, :, :, 0]\n",
    "            plt.imshow(the_input.T, cmap='Greys_r')\n",
    "            plt.xlabel('Truth = \\'%s\\'\\nDecoded = \\'%s\\'' % (word_batch['source_str'][i], res[i]))\n",
    "        fig = pylab.gcf()\n",
    "        fig.set_size_inches(10, 13)\n",
    "        plt.savefig(os.path.join(self.output_dir, 'e%02d.png' % (epoch)))\n",
    "        plt.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "eC4vEfcQ5oOq"
   },
   "outputs": [],
   "source": [
    "img_gen = None\n",
    "def train(run_name, start_epoch, stop_epoch, img_w):\n",
    "    global img_gen\n",
    "    img_h = 64\n",
    "    \n",
    "    # Input Parameters\n",
    "\n",
    "    words_per_epoch = 16000\n",
    "    val_split = 0.2\n",
    "    \n",
    "    # 16000 * 0.2 = 3200\n",
    "    val_words = int(words_per_epoch * (val_split))\n",
    "\n",
    "    # Network parameters\n",
    "    minibatch_size = 32\n",
    "    \n",
    "    \n",
    "    # (16000 - 3200) // 32 = 400\n",
    "    steps_per_epoch = (words_per_epoch - val_words) // minibatch_size\n",
    "\n",
    "\n",
    "    if generator_choice == \"Text_Image\":\n",
    "        fdir = os.path.dirname(get_file('wordlists.tgz',\n",
    "                                        origin='http://www.mythic-ai.com/datasets/wordlists.tgz', untar=True))\n",
    "\n",
    "        img_gen = GTI.TextImageGenerator(monogram_file=os.path.join(fdir, 'wordlist_mono_clean.txt'),\n",
    "                                     bigram_file=os.path.join(fdir, 'wordlist_bi_clean.txt'),\n",
    "                                     minibatch_size=minibatch_size,\n",
    "                                     img_w=img_w,\n",
    "                                     img_h=img_h,\n",
    "                                     downsample_factor=(pool_size ** 2),\n",
    "                                     val_split=words_per_epoch - val_words\n",
    "                                     )\n",
    "    elif generator_choice == \"Script_Image\":\n",
    "        img_gen = IAM.IAM_Word_Generator(minibatch_size = 32, img_w = img_w, img_h = img_h, downsample_factor=4, absolute_max_string_len=16)\n",
    "    else:\n",
    "        assert False\n",
    "\n",
    "    model, input_data, y_pred = cnn_rnn_model.make_model(img_w, img_h, img_gen.get_output_size(), img_gen.absolute_max_string_len)\n",
    "    \n",
    "    \n",
    "    model.summary() # print summary of model\n",
    "\n",
    "    # clipnorm seems to speeds up convergence\n",
    "    sgd = SGD(lr=0.02, decay=1e-6, momentum=0.9, nesterov=True, clipnorm=5)\n",
    "    \n",
    "    # the loss calc occurs elsewhere, so use a dummy lambda func for the loss\n",
    "    model.compile(loss={'ctc': lambda y_true, y_pred: y_pred}, optimizer=sgd)\n",
    "    if start_epoch > 0:\n",
    "        weight_file = os.path.join(OUTPUT_DIR, os.path.join(run_name, 'weights%02d.h5' % (start_epoch - 1)))\n",
    "        model.load_weights(weight_file)\n",
    "    # captures output of softmax so we can decode the output during visualization\n",
    "    test_func = K.function([input_data], [y_pred])\n",
    "\n",
    "    viz_cb = VizCallback(run_name, test_func, img_gen.next_val())\n",
    "\n",
    "    model.fit_generator(generator=img_gen.next_train(),\n",
    "                        steps_per_epoch=steps_per_epoch,\n",
    "                        epochs=stop_epoch,\n",
    "                        validation_data=img_gen.next_val(),\n",
    "                        validation_steps=val_words // minibatch_size,\n",
    "                        callbacks=[viz_cb, img_gen],\n",
    "                        initial_epoch=start_epoch)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "13kO-MxI7XWb"
   },
   "source": [
    "### Start the training\n",
    "\n",
    "1080ti run times: \n",
    "- 12 minutes for 20/20 epoch\n",
    "- 25 minutes for 25/25 epoch\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 2094
    },
    "colab_type": "code",
    "id": "YRGglF5L5qzn",
    "outputId": "541e795b-80d1-49e6-9c9f-e2014690f4a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensor(\"the_labels_2:0\", shape=(?, 16), dtype=float32)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_input (InputLayer)          (None, 128, 64, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 128, 64, 16)  160         the_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max1 (MaxPooling2D)             (None, 64, 32, 16)   0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 64, 32, 16)   2320        max1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "max2 (MaxPooling2D)             (None, 32, 16, 16)   0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 32, 256)      0           max2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 32, 32)       8224        reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru1 (GRU)                      (None, 32, 512)      837120      dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru1_b (GRU)                    (None, 32, 512)      837120      dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_3 (Add)                     (None, 32, 512)      0           gru1[0][0]                       \n",
      "                                                                 gru1_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru2 (GRU)                      (None, 32, 512)      1574400     add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gru2_b (GRU)                    (None, 32, 512)      1574400     add_3[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 32, 1024)     0           gru2[0][0]                       \n",
      "                                                                 gru2_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 32, 54)       55350       concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, 32, 54)       0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "the_labels (InputLayer)         (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "label_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ctc (Lambda)                    (None, 1)            0           softmax[0][0]                    \n",
      "                                                                 the_labels[0][0]                 \n",
      "                                                                 input_length[0][0]               \n",
      "                                                                 label_length[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 4,889,094\n",
      "Trainable params: 4,889,094\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "on_train_begin\n",
      "Epoch 1/20\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 36s 90ms/step - loss: 12.6481 - val_loss: 12.4251\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 2.586 Mean normalized edit distance: 0.773\n",
      "Epoch 2/20\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 33s 81ms/step - loss: 9.0071 - val_loss: 7.8179\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 2.164 Mean normalized edit distance: 0.659\n",
      "Epoch 3/20\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 33s 83ms/step - loss: 7.6121 - val_loss: 7.2527\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 1.918 Mean normalized edit distance: 0.561\n",
      "Epoch 4/20\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 81ms/step - loss: 6.7713 - val_loss: 6.2734\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 1.652 Mean normalized edit distance: 0.497\n",
      "Epoch 5/20\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 81ms/step - loss: 6.1938 - val_loss: 6.1228\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 1.668 Mean normalized edit distance: 0.473\n",
      "Epoch 6/20\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 33s 82ms/step - loss: 5.8212 - val_loss: 5.4253\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 1.465 Mean normalized edit distance: 0.392\n",
      "Epoch 7/20\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 33s 81ms/step - loss: 5.5285 - val_loss: 5.2410\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 1.461 Mean normalized edit distance: 0.409\n",
      "Epoch 8/20\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 33s 82ms/step - loss: 5.1585 - val_loss: 5.3761\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 1.469 Mean normalized edit distance: 0.398\n",
      "Epoch 9/20\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 33s 81ms/step - loss: 4.8473 - val_loss: 4.5599\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 1.324 Mean normalized edit distance: 0.322\n",
      "Epoch 10/20\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 81ms/step - loss: 4.5432 - val_loss: 4.3541\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 1.246 Mean normalized edit distance: 0.322\n",
      "Epoch 11/20\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 34s 84ms/step - loss: 4.4177 - val_loss: 4.4040\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 1.266 Mean normalized edit distance: 0.322\n",
      "Epoch 12/20\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 81ms/step - loss: 4.2031 - val_loss: 4.3942\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 1.273 Mean normalized edit distance: 0.334\n",
      "Epoch 13/20\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 33s 82ms/step - loss: 4.1104 - val_loss: 3.8943\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 1.117 Mean normalized edit distance: 0.277\n",
      "Epoch 14/20\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 33s 83ms/step - loss: 3.8464 - val_loss: 3.7331\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 1.082 Mean normalized edit distance: 0.271\n",
      "Epoch 15/20\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 33s 82ms/step - loss: 3.7440 - val_loss: 3.6259\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 1.008 Mean normalized edit distance: 0.277\n",
      "Epoch 16/20\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 33s 81ms/step - loss: 3.5074 - val_loss: 3.2936\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.867 Mean normalized edit distance: 0.249\n",
      "Epoch 17/20\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 81ms/step - loss: 3.4571 - val_loss: 3.0887\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.844 Mean normalized edit distance: 0.203\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 18/20\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 81ms/step - loss: 3.3716 - val_loss: 3.1104\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.957 Mean normalized edit distance: 0.240\n",
      "Epoch 19/20\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 32s 81ms/step - loss: 3.1865 - val_loss: 3.0535\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.824 Mean normalized edit distance: 0.220\n",
      "Epoch 20/20\n",
      "on_epoch_begin\n",
      "400/400 [==============================] - 33s 82ms/step - loss: 3.1467 - val_loss: 3.1441\n",
      "\n",
      "Out of 256 samples:  Mean edit distance: 0.848 Mean normalized edit distance: 0.249\n",
      "Tensor(\"the_labels_3:0\", shape=(?, 16), dtype=float32)\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "the_input (InputLayer)          (None, 512, 64, 1)   0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv1 (Conv2D)                  (None, 512, 64, 16)  160         the_input[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "max1 (MaxPooling2D)             (None, 256, 32, 16)  0           conv1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "conv2 (Conv2D)                  (None, 256, 32, 16)  2320        max1[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "max2 (MaxPooling2D)             (None, 128, 16, 16)  0           conv2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "reshape (Reshape)               (None, 128, 256)     0           max2[0][0]                       \n",
      "__________________________________________________________________________________________________\n",
      "dense1 (Dense)                  (None, 128, 32)      8224        reshape[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "gru1 (GRU)                      (None, 128, 512)     837120      dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru1_b (GRU)                    (None, 128, 512)     837120      dense1[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "add_4 (Add)                     (None, 128, 512)     0           gru1[0][0]                       \n",
      "                                                                 gru1_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "gru2 (GRU)                      (None, 128, 512)     1574400     add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "gru2_b (GRU)                    (None, 128, 512)     1574400     add_4[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 128, 1024)    0           gru2[0][0]                       \n",
      "                                                                 gru2_b[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense2 (Dense)                  (None, 128, 54)      55350       concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "softmax (Activation)            (None, 128, 54)      0           dense2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "the_labels (InputLayer)         (None, 16)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "label_length (InputLayer)       (None, 1)            0                                            \n",
      "__________________________________________________________________________________________________\n",
      "ctc (Lambda)                    (None, 1)            0           softmax[0][0]                    \n",
      "                                                                 the_labels[0][0]                 \n",
      "                                                                 input_length[0][0]               \n",
      "                                                                 label_length[0][0]               \n",
      "==================================================================================================\n",
      "Total params: 4,889,094\n",
      "Trainable params: 4,889,094\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "on_train_begin\n",
      "Epoch 21/25\n",
      "on_epoch_begin\n",
      "399/400 [============================>.] - ETA: 0s - loss: 6.5056"
     ]
    }
   ],
   "source": [
    "run_name = datetime.datetime.now().strftime('%Y:%m:%d:%H:%M:%S')\n",
    "train(run_name, 0, 20, 128)\n",
    "# increase to wider images and start at epoch 20. The learned weights are reloaded\n",
    "img_gen.set_img_w(512)\n",
    "train(run_name, 20, 25, 512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "image_ocr.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
