{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "see README.md"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     },
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 7776,
     "status": "ok",
     "timestamp": 1526105952629,
     "user": {
      "displayName": "Chengwei Zhang",
      "photoUrl": "//lh5.googleusercontent.com/-FK2ckwmh6mM/AAAAAAAAAAI/AAAAAAAAPLw/SX9b1QAzJ5g/s50-c-k-no/photo.jpg",
      "userId": "114808171854651597062"
     },
     "user_tz": -480
    },
    "id": "1wsDPx682A7H",
    "outputId": "88ee055c-b674-4a81-c869-8401551f09d7"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import itertools\n",
    "\n",
    "\n",
    "import datetime\n",
    "\n",
    "import editdistance\n",
    "import numpy as np\n",
    "\n",
    "import pylab\n",
    "import matplotlib.pyplot as plt\n",
    "from keras import backend as K\n",
    "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
    "from keras.layers import Input, Dense, Activation\n",
    "from keras.layers import Reshape, Lambda\n",
    "from keras.layers.merge import add, concatenate\n",
    "from keras.models import Model\n",
    "from keras.layers.recurrent import GRU\n",
    "from keras.optimizers import SGD\n",
    "from keras.utils.data_utils import get_file\n",
    "from keras.preprocessing import image\n",
    "import keras.callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "Xnj6R_OE3yMl"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "np.random.seed(55)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "autoexec": {
      "startup": false,
      "wait_interval": 0
     }
    },
    "colab_type": "code",
    "id": "mM0eHsJO5bP6"
   },
   "outputs": [],
   "source": [
    "import generator_text_image as fake\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify what we have with existing generator\n",
    "def lets_understand():\n",
    "    \n",
    "    img_w = 128\n",
    "    img_h = 64\n",
    "    pool_size = 2\n",
    "    words_per_epoch = 16000\n",
    "    val_split = 0.2\n",
    "    val_words = int(words_per_epoch * (val_split))\n",
    "    minibatch_size = 32\n",
    "    \n",
    "    print(\"INPUT to generator:\")\n",
    "    print()\n",
    "    print(K.image_data_format())\n",
    "    if K.image_data_format() == 'channels_first':\n",
    "        input_shape = (1, img_w, img_h)\n",
    "    else:\n",
    "        input_shape = (img_w, img_h, 1)\n",
    "\n",
    "    fdir = os.path.dirname(get_file('wordlists.tgz',\n",
    "                                    origin='http://www.mythic-ai.com/datasets/wordlists.tgz', untar=True))\n",
    "\n",
    "    print(\"img_w\", img_w)\n",
    "    print(\"img_h\", img_h)\n",
    "    print(\"pool_size\", pool_size)\n",
    "    print(\"words_per_epoch\", words_per_epoch)\n",
    "    print(\"val_words\", val_words)\n",
    "    img_gen = fake.TextImageGenerator(monogram_file=os.path.join(fdir, 'wordlist_mono_clean.txt'),\n",
    "                                 bigram_file=os.path.join(fdir, 'wordlist_bi_clean.txt'),\n",
    "                                 minibatch_size=minibatch_size,\n",
    "                                 img_w=img_w,\n",
    "                                 img_h=img_h,\n",
    "                                 downsample_factor=(pool_size ** 2),\n",
    "                                 val_split=words_per_epoch - val_words\n",
    "                                 )\n",
    "    \n",
    "    print()\n",
    "    print(\"OUTPUT to generator:\")\n",
    "    print()\n",
    "    print(\"img_gen.get_output_size()\", img_gen.get_output_size())\n",
    "    print(\"img_gen.absolute_max_string_len\", img_gen.absolute_max_string_len)\n",
    "    img_gen.on_train_begin()\n",
    "    \n",
    "    temp = img_gen.next_train() # output is dummy data according to comments\n",
    "    \n",
    "    for i in temp:\n",
    "        temp_input, temp_output_is_dummy = i\n",
    "        \n",
    "        print()\n",
    "        print('this corresponds to cnn_rnn_model Input(name=the_input')\n",
    "        print(\"the_input is a set of images \", temp_input['the_input'].shape)\n",
    "        \n",
    "        print()\n",
    "        print(\"source_str for visualization\", temp_input['source_str'][:8])\n",
    "        \n",
    "        print()\n",
    "        print(\"the next are inputs to the model for ctc calculation\")\n",
    "        print()\n",
    "        print(\"this corresponds to cnn_rnn_model Input(name='the_labels'\")\n",
    "        print(\"the_labels are char index from a, ex:t=19\")\n",
    "        print(temp_input['the_labels'][:2])\n",
    "        \n",
    "        print()\n",
    "        print(\"this corresponds to cnn_rnn_model Input(name='input_length'\")\n",
    "        print('input_length of ctc is 2 short, see ctc_drop_first_2')\n",
    "        print(temp_input['input_length'][:2])\n",
    "        \n",
    "        print()\n",
    "        print(\"this corresponds to cnn_rnn_model Input(name='label_length'\")\n",
    "        print('label_length is number of chars in word')\n",
    "        print(temp_input['label_length'][:8])\n",
    "        \n",
    "        break\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INPUT to generator:\n",
      "\n",
      "channels_last\n",
      "img_w 128\n",
      "img_h 64\n",
      "pool_size 2\n",
      "words_per_epoch 16000\n",
      "val_words 3200\n",
      "\n",
      "OUTPUT to generator:\n",
      "\n",
      "img_gen.get_output_size() 28\n",
      "img_gen.absolute_max_string_len 16\n",
      "\n",
      "this corresponds to cnn_rnn_model Input(name=the_input\n",
      "the_input is a set of images  (32, 128, 64, 1)\n",
      "\n",
      "source_str for visualization ['the', 'rmp', 'of', 'arpt', 'and', 'axon', 'to', 'pdo']\n",
      "\n",
      "the next are inputs to the model for ctc calculation\n",
      "this corresponds to cnn_rnn_model Input(name='the_labels'\n",
      "the_labels are char index from a, ex:t=19\n",
      "[[19.  7.  4. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]\n",
      " [17. 12. 15. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1. -1.]]\n",
      "\n",
      "this corresponds to cnn_rnn_model Input(name='input_length'\n",
      "input_length of ctc is 2 short, see ctc_drop_first_2\n",
      "[[30.]\n",
      " [30.]]\n",
      "\n",
      "this corresponds to cnn_rnn_model Input(name='label_length'\n",
      "label_length is number of chars in word\n",
      "[[3.]\n",
      " [3.]\n",
      " [2.]\n",
      " [4.]\n",
      " [3.]\n",
      " [4.]\n",
      " [2.]\n",
      " [3.]]\n"
     ]
    }
   ],
   "source": [
    "lets_understand()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "default_view": {},
   "name": "image_ocr.ipynb",
   "provenance": [],
   "version": "0.3.2",
   "views": {}
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
